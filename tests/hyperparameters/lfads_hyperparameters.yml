# example hyperparameter definitions for the tspred LFADS model experiment

# datamodule hyperparameters
datamodule:
  name: gw250
  src_len: 50
  trg_len: 50
  batch_size: 750

# model hyperparamters
model:
  name: Lfads # this is currently the class name, might want a different ID
  # encoder hyperparameters (GRU)
  encoder_hidden_size: 1024
  encoder_num_layers: 1
  encoder_bidirectional: True
  # decoder hyperparameters (GRU)
  generator_hidden_size: 1024
  generator_num_layers: 1
  generator_bidirectional: False
  # generator IC prior hyperparameters (gaussian)
  generator_ic_prior:
    mean: 0 # these were previously set to "learnable" here, but perhaps that should be in the script?
    logvar: 1
  # misc
  dropout: 0.3

# Lfads objective (loss + regularization) weights
objective: #TODO: rename this?
  name: MSELoss
  kl:
    weight : 0.0
    min: 0.0
    max: 0.0005 # subject to hyperparameter optimization
    schedule_dur: 2000
    schedule_start: 0
  l2:
    weight: 0.0
    min: 0.0
    max: 0.0005
    schedule_dur: 2000
    schedule_start: 0.0

# ADAM optimizer hyperparameters
optimizer:
  name: ADAM
  lr: 0.001
  betas: !!python/tuple
  - 0.9
  - 0.99
  eps: 0.1
  scheduler: ReduceLROnPlateau
  min_lr: 1.0e-05
  factor: 0.95
  patience: 6
  cooldown: 0

# Pytorch-Lightning trainer hyperparamters
trainer:
  gradient_clip_val: 200
  gradient_clip_algorithm: value
  min_epochs: 100
  max_epochs: 500